{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5606687684e64c9a944291a636ec0976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_791c72e1fdb84b97bf66cc820dff9077",
              "IPY_MODEL_5f6a104d1828430986a70f0da90eb707",
              "IPY_MODEL_22159a68e8624cc4820e688caeda837f"
            ],
            "layout": "IPY_MODEL_ed064bbbee7b429fb03810ea834cd030"
          }
        },
        "791c72e1fdb84b97bf66cc820dff9077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f44e14faa894ed780575b57d5f74579",
            "placeholder": "​",
            "style": "IPY_MODEL_8a4b4608fedc44259a3c023e0c4847a9",
            "value": "Map: 100%"
          }
        },
        "5f6a104d1828430986a70f0da90eb707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b32c67658cc4e42ba01ab5c49613ca0",
            "max": 36718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc8275a47cc5467c9ad3c24e02f9face",
            "value": 36718
          }
        },
        "22159a68e8624cc4820e688caeda837f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a976a77618b479ba1c98af21632a760",
            "placeholder": "​",
            "style": "IPY_MODEL_8cc5ac71ce2e41938bf2f0899da3859a",
            "value": " 36718/36718 [00:12&lt;00:00, 5021.80 examples/s]"
          }
        },
        "ed064bbbee7b429fb03810ea834cd030": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f44e14faa894ed780575b57d5f74579": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a4b4608fedc44259a3c023e0c4847a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b32c67658cc4e42ba01ab5c49613ca0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc8275a47cc5467c9ad3c24e02f9face": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a976a77618b479ba1c98af21632a760": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cc5ac71ce2e41938bf2f0899da3859a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b08bc56d51448fbb8d7c67afa1bad5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8fb78e66c0f14593b4d15574f5e4a83e",
              "IPY_MODEL_44a7c34cc3e141518716f7718b0256e8",
              "IPY_MODEL_a8d2f3c18c3b48c5aad33e2baea4581c"
            ],
            "layout": "IPY_MODEL_11bc7a35c16847e9998eedbd934c0932"
          }
        },
        "8fb78e66c0f14593b4d15574f5e4a83e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5faac1cbb2454cb8b738f1f5c1bd7e8b",
            "placeholder": "​",
            "style": "IPY_MODEL_a9a1247f7e514fffbac602a486f06327",
            "value": "Map: 100%"
          }
        },
        "44a7c34cc3e141518716f7718b0256e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9a0b3de43cf447abfb9582da9435c0c",
            "max": 36718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_783ad3ed6c3e4ad8ad02f3c0cf03b0ab",
            "value": 36718
          }
        },
        "a8d2f3c18c3b48c5aad33e2baea4581c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cc7017c6adb4424aca05065a733d3c5",
            "placeholder": "​",
            "style": "IPY_MODEL_91baf3d72fe44bfdb193769eb476eb73",
            "value": " 36718/36718 [00:04&lt;00:00, 6716.26 examples/s]"
          }
        },
        "11bc7a35c16847e9998eedbd934c0932": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5faac1cbb2454cb8b738f1f5c1bd7e8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9a1247f7e514fffbac602a486f06327": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9a0b3de43cf447abfb9582da9435c0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "783ad3ed6c3e4ad8ad02f3c0cf03b0ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6cc7017c6adb4424aca05065a733d3c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91baf3d72fe44bfdb193769eb476eb73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30787,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanghae-plus-AI/AI-1-csn2506/blob/main/week6/Chapter4_1_%EA%B8%B0%EB%B3%B8%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4-1- 기본과제\n",
        "\n",
        "## Validation data를 포함하여 Fine-tuning 해보기"
      ],
      "metadata": {
        "id": "3EEKHAt9Ksyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTIjd9RlI-o-",
        "outputId": "01c2b3e4-3aa3-4e4f-d48f-586429099ebd",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-23T14:05:59.85662Z",
          "iopub.execute_input": "2024-10-23T14:05:59.857314Z",
          "iopub.status.idle": "2024-10-23T14:06:12.830159Z",
          "shell.execute_reply.started": "2024-10-23T14:05:59.85726Z",
          "shell.execute_reply": "2024-10-23T14:06:12.829229Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import sys\n",
        "\n",
        "import math\n",
        "\n",
        "import torch\n",
        "\n",
        "import wandb\n",
        "\n",
        "import logging\n",
        "\n",
        "import datasets\n",
        "\n",
        "import argparse\n",
        "\n",
        "import evaluate\n",
        "\n",
        "import transformers\n",
        "\n",
        "\n",
        "\n",
        "from typing import Optional\n",
        "\n",
        "from itertools import chain\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "\n",
        "\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "from transformers import (\n",
        "\n",
        "    AutoConfig,\n",
        "\n",
        "    AutoModelForCausalLM,\n",
        "\n",
        "    AutoTokenizer,\n",
        "\n",
        "    HfArgumentParser,\n",
        "\n",
        "    Trainer,\n",
        "\n",
        "    TrainingArguments,\n",
        "\n",
        "    default_data_collator\n",
        "\n",
        ")\n",
        "\n",
        "from transformers.trainer_utils import get_last_checkpoint"
      ],
      "metadata": {
        "id": "OfVbcKWXKEiA",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-23T14:06:12.832323Z",
          "iopub.execute_input": "2024-10-23T14:06:12.832739Z",
          "iopub.status.idle": "2024-10-23T14:06:35.333145Z",
          "shell.execute_reply.started": "2024-10-23T14:06:12.832692Z",
          "shell.execute_reply": "2024-10-23T14:06:35.332365Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project='Chapter4-1-basic')\n",
        "\n",
        "wandb.run.name = 'gpts-finetuning'"
      ],
      "metadata": {
        "id": "kfQrVZS9KNX7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215,
          "referenced_widgets": [
            "cfcb36799cad4b91a7a3a66aee00603c"
          ]
        },
        "outputId": "03ccf906-60b3-45a2-ce8b-aab1ca4053ec",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-23T14:06:35.334263Z",
          "iopub.execute_input": "2024-10-23T14:06:35.334826Z",
          "iopub.status.idle": "2024-10-23T14:07:05.731808Z",
          "shell.execute_reply.started": "2024-10-23T14:06:35.334794Z",
          "shell.execute_reply": "2024-10-23T14:07:05.73083Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:",
          "output_type": "stream"
        },
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "  ········\n"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113988600000842, max=1.0…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfcb36799cad4b91a7a3a66aee00603c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.18.3"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20241023_140702-2oesg8d4</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/csn2506-diem/Chapter4-1-basic/runs/2oesg8d4' target=\"_blank\">sparkling-gorge-2</a></strong> to <a href='https://wandb.ai/csn2506-diem/Chapter4-1-basic' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/csn2506-diem/Chapter4-1-basic' target=\"_blank\">https://wandb.ai/csn2506-diem/Chapter4-1-basic</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/csn2506-diem/Chapter4-1-basic/runs/2oesg8d4' target=\"_blank\">https://wandb.ai/csn2506-diem/Chapter4-1-basic/runs/2oesg8d4</a>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "\n",
        "class Arguments:\n",
        "\n",
        "    model_name_or_path: Optional[str] = field(default=None)  # HuggingFace hub에서 pre-trained 모델로 사용할 모델의 이름\n",
        "\n",
        "    torch_dtype: Optional[str] = field(default=None, metadata={'choices': ['auto', 'bfloat16', 'float16', 'float32']})  # 우리 모델의 precision(data type이라고 이해하시면 됩니다)\n",
        "\n",
        "\n",
        "\n",
        "    dataset_name: Optional[str] = field(default=None)  # Fine-tuning으로 사용할 huggingface hub에서의 dataset 이름\n",
        "\n",
        "    dataset_config_name: Optional[str] = field(default=None)  # Fine-tuning으로 사용할 huggingface hub에서의 dataset configuration\n",
        "\n",
        "    block_size: int = field(default=1024)  # Fine-tuning에 사용할 input text의 길이\n",
        "\n",
        "    num_workers: Optional[int] = field(default=None)  # Data를 업로드하거나 전처리할 때 사용할 worker 숫자\n",
        "\n",
        "\n",
        "\n",
        "import sys\n",
        "\n",
        "sys.argv = [\n",
        "\n",
        "    sys.argv[0],\n",
        "\n",
        "    \"--output_dir\", \"./output\",\n",
        "\n",
        "    \"--per_device_train_batch_size\", \"8\",\n",
        "\n",
        "    \"--per_device_eval_batch_size\", \"8\",\n",
        "\n",
        "    \"--num_train_epochs\", \"3\",\n",
        "\n",
        "    \"--logging_dir\", \"./logs\",\n",
        "\n",
        "    \"--dataset_name\", \"wikitext\",\n",
        "\n",
        "    \"--model_name_or_path\", \"openai-community/openai-gpt\",\n",
        "\n",
        "    \"--dataset_config_name\", \"wikitext-2-raw-v1\",\n",
        "\n",
        "    \"--do_train\",\n",
        "\n",
        "    \"--save_total_limit\", \"1\",\n",
        "\n",
        "    \"--logging_steps\", \"100\",\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "parser = HfArgumentParser((Arguments, TrainingArguments))\n",
        "\n",
        "args, training_args = parser.parse_args_into_dataclasses()\n",
        "\n",
        "\n",
        "\n",
        "logger = logging.getLogger()\n",
        "\n",
        "\n",
        "\n",
        "logging.basicConfig(\n",
        "\n",
        "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
        "\n",
        "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "\n",
        "    handlers=[logging.StreamHandler(sys.stdout)],\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "if training_args.should_log:\n",
        "\n",
        "    transformers.utils.logging.set_verbosity_info()  # log level을 INFO로 변경\n",
        "\n",
        "\n",
        "\n",
        "log_level = training_args.get_process_log_level()\n",
        "\n",
        "logger.setLevel(log_level)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 우리가 가지고 있는 logger와 HuggingFace의 logger의 log level 설정\n",
        "\n",
        "logger.setLevel(log_level)\n",
        "\n",
        "datasets.utils.logging.set_verbosity(log_level)\n",
        "\n",
        "transformers.utils.logging.set_verbosity(log_level)\n",
        "\n",
        "\n",
        "\n",
        "# 기타 HuggingFace logger option들을 설정\n",
        "\n",
        "transformers.utils.logging.enable_default_handler()\n",
        "\n",
        "transformers.utils.logging.enable_explicit_format()\n",
        "\n",
        "\n",
        "\n",
        "logger.info(f\"Training/evaluation parameters {training_args}\")"
      ],
      "metadata": {
        "id": "UHZ--LQcKO7C",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-23T14:07:05.734856Z",
          "iopub.execute_input": "2024-10-23T14:07:05.735401Z",
          "iopub.status.idle": "2024-10-23T14:07:05.829888Z",
          "shell.execute_reply.started": "2024-10-23T14:07:05.735355Z",
          "shell.execute_reply": "2024-10-23T14:07:05.829142Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터셋 로드"
      ],
      "metadata": {
        "id": "fnc5A9qXwyaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "raw_datasets = load_dataset(\n",
        "\n",
        "    args.dataset_name,\n",
        "\n",
        "    args.dataset_config_name\n",
        "\n",
        ")\n"
      ],
      "metadata": {
        "id": "4a5IzL1VKStS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "a4d653eb833a4e748a6a3308d2fa0403",
            "75ea003b2d1f42cb9108034dcd5cb76c",
            "d45459d6ca2241148e41b0a853122ff0",
            "2b8838933b7f4c6bb2e8fd18329aae39",
            "4d67beb37a604b88beda5d1d32a5bedc",
            "4b8cb444698747f0ac91441731a82236",
            "7fdeaa1fbd1140e5a9470f439de6933e"
          ]
        },
        "outputId": "83555595-5570-4845-a831-8a3c5fcde80e",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-23T14:07:05.831034Z",
          "iopub.execute_input": "2024-10-23T14:07:05.831346Z",
          "iopub.status.idle": "2024-10-23T14:07:10.757711Z",
          "shell.execute_reply.started": "2024-10-23T14:07:05.831313Z",
          "shell.execute_reply": "2024-10-23T14:07:10.7569Z"
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4d653eb833a4e748a6a3308d2fa0403"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Generating dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3)\nDownloading and preparing dataset wikitext/wikitext-2-raw-v1 to /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "test-00000-of-00001.parquet:   0%|          | 0.00/733k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75ea003b2d1f42cb9108034dcd5cb76c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "train-00000-of-00001.parquet:   0%|          | 0.00/6.36M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d45459d6ca2241148e41b0a853122ff0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "validation-00000-of-00001.parquet:   0%|          | 0.00/657k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b8838933b7f4c6bb2e8fd18329aae39"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Downloading took 0.0 min\nChecksum Computation took 0.0 min\nGenerating test split\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d67beb37a604b88beda5d1d32a5bedc"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Generating train split\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/36718 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b8cb444698747f0ac91441731a82236"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Generating validation split\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7fdeaa1fbd1140e5a9470f439de6933e"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "All the splits matched successfully.\nDataset wikitext downloaded and prepared to /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3. Subsequent calls will reuse this data.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "config = AutoConfig.from_pretrained(args.model_name_or_path)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(args.model_name_or_path)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "\n",
        "    args.model_name_or_path,\n",
        "\n",
        "    config=config,\n",
        "\n",
        "    torch_dtype=args.torch_dtype\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "tokenizer.chat_template = \"{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}\"\n",
        "\n",
        "\n",
        "\n",
        "embedding_size = model.get_input_embeddings().weight.shape[0]\n",
        "\n",
        "if len(tokenizer) > embedding_size:\n",
        "\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "\n",
        "\n",
        "column_names = list(raw_datasets[\"train\"].features)\n",
        "\n",
        "text_column_name = \"text\" if \"text\" in column_names else column_names[0]\n",
        "\n",
        "\n",
        "\n",
        "def tokenize_function(examples):\n",
        "\n",
        "    output = tokenizer(examples[text_column_name])\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "with training_args.main_process_first(desc=\"dataset map tokenization\"):\n",
        "\n",
        "    tokenized_datasets = raw_datasets.map(\n",
        "\n",
        "        tokenize_function,\n",
        "\n",
        "        batched=True,\n",
        "\n",
        "        num_proc=args.num_workers,\n",
        "\n",
        "        remove_columns=column_names\n",
        "\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "max_pos_embeddings = config.max_position_embeddings if hasattr(config, \"max_position_embeddings\") else 1024\n",
        "\n",
        "block_size = args.block_size if tokenizer.model_max_length is None else min(args.block_size, tokenizer.model_max_length)\n",
        "\n",
        "\n",
        "\n",
        "def group_texts(examples):\n",
        "\n",
        "    # 주어진 text들을 모두 concat 해줍니다.\n",
        "\n",
        "    # 예를 들어 examples = {'train': [['Hello!'], ['Yes, that is great!']]}이면 결과물은 {'train': ['Hello! Yes, that is great!']}가 됩니다.\n",
        "\n",
        "    concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n",
        "\n",
        "\n",
        "\n",
        "    # 전체 길이를 측정합니다.\n",
        "\n",
        "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
        "\n",
        "    total_length = (total_length // block_size) * block_size\n",
        "\n",
        "\n",
        "\n",
        "    # block_size로 text를 쪼갭니다.\n",
        "\n",
        "    # 예를 들어 block_size=3일 때 {'train': ['Hello! Yes, that is great!']}는\n",
        "\n",
        "    # {'train': ['Hel', 'lo!', ' Ye', 's, ', 'tha', ...]}가 됩니다.\n",
        "\n",
        "    result = {\n",
        "\n",
        "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
        "\n",
        "        for k, t in concatenated_examples.items()\n",
        "\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "    # Next token prediction이니 label은 자기 자신으로 설정합니다.\n",
        "\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "with training_args.main_process_first(desc=\"grouping texts together\"):\n",
        "\n",
        "    lm_datasets = tokenized_datasets.map(\n",
        "\n",
        "        group_texts,\n",
        "\n",
        "        batched=True,\n",
        "\n",
        "        num_proc=args.num_workers\n",
        "\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5606687684e64c9a944291a636ec0976",
            "791c72e1fdb84b97bf66cc820dff9077",
            "5f6a104d1828430986a70f0da90eb707",
            "22159a68e8624cc4820e688caeda837f",
            "ed064bbbee7b429fb03810ea834cd030",
            "5f44e14faa894ed780575b57d5f74579",
            "8a4b4608fedc44259a3c023e0c4847a9",
            "8b32c67658cc4e42ba01ab5c49613ca0",
            "cc8275a47cc5467c9ad3c24e02f9face",
            "2a976a77618b479ba1c98af21632a760",
            "8cc5ac71ce2e41938bf2f0899da3859a",
            "5b08bc56d51448fbb8d7c67afa1bad5f",
            "8fb78e66c0f14593b4d15574f5e4a83e",
            "44a7c34cc3e141518716f7718b0256e8",
            "a8d2f3c18c3b48c5aad33e2baea4581c",
            "11bc7a35c16847e9998eedbd934c0932",
            "5faac1cbb2454cb8b738f1f5c1bd7e8b",
            "a9a1247f7e514fffbac602a486f06327",
            "f9a0b3de43cf447abfb9582da9435c0c",
            "783ad3ed6c3e4ad8ad02f3c0cf03b0ab",
            "6cc7017c6adb4424aca05065a733d3c5",
            "91baf3d72fe44bfdb193769eb476eb73",
            "ccc05fb0b3404473afe259c97a8d39a3",
            "dda75cfaa75e4ffd85075d041ac1414b",
            "553de79dfaab4a3f988adacb66975b58",
            "61403905747d4cb6bda35a9627f63032",
            "7e395f6ad8014b6c91b52636fcff66d1",
            "3b9cbb2430b3481d9ab6ae53e73a1342",
            "164d938393f5449db0e2695e287e765b",
            "ea44bed0fe1945eca91d8adb967cf853",
            "bbaad39eab4049179a4c31642c239b2e",
            "2332ec87b510496ea6430f0fb755a573",
            "833910866ef64cff852a26b1398c4ba3",
            "41dd208feec54475ac7ca7908e0a4eea",
            "38e207d8e11340cfa90c50b2807a482d"
          ]
        },
        "id": "w3hS9bH70cvl",
        "outputId": "13fed5c7-8eae-472a-ea66-c38481086136",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-23T14:07:10.759062Z",
          "iopub.execute_input": "2024-10-23T14:07:10.759355Z",
          "iopub.status.idle": "2024-10-23T14:07:25.66518Z",
          "shell.execute_reply.started": "2024-10-23T14:07:10.759323Z",
          "shell.execute_reply": "2024-10-23T14:07:25.664257Z"
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/656 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ccc05fb0b3404473afe259c97a8d39a3"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "[INFO|configuration_utils.py:672] 2024-10-23 14:07:10,944 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--openai-community--openai-gpt/snapshots/1e0d4f3028acbffb47fe933cea64619c5ec1a002/config.json\n[INFO|configuration_utils.py:739] 2024-10-23 14:07:10,948 >> Model config OpenAIGPTConfig {\n  \"_name_or_path\": \"openai-community/openai-gpt\",\n  \"afn\": \"gelu\",\n  \"architectures\": [\n    \"OpenAIGPTLMHeadModel\"\n  ],\n  \"attn_pdrop\": 0.1,\n  \"embd_pdrop\": 0.1,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"openai-gpt\",\n  \"n_ctx\": 512,\n  \"n_embd\": 768,\n  \"n_head\": 12,\n  \"n_layer\": 12,\n  \"n_positions\": 512,\n  \"n_special\": 0,\n  \"predict_special_tokens\": true,\n  \"resid_pdrop\": 0.1,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"task_specific_params\": {\n    \"text-generation\": {\n      \"do_sample\": true,\n      \"max_length\": 50\n    }\n  },\n  \"transformers_version\": \"4.45.1\",\n  \"vocab_size\": 40478\n}\n\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dda75cfaa75e4ffd85075d041ac1414b"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "[INFO|configuration_utils.py:672] 2024-10-23 14:07:11,126 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--openai-community--openai-gpt/snapshots/1e0d4f3028acbffb47fe933cea64619c5ec1a002/config.json\n[INFO|configuration_utils.py:739] 2024-10-23 14:07:11,128 >> Model config OpenAIGPTConfig {\n  \"_name_or_path\": \"openai-community/openai-gpt\",\n  \"afn\": \"gelu\",\n  \"architectures\": [\n    \"OpenAIGPTLMHeadModel\"\n  ],\n  \"attn_pdrop\": 0.1,\n  \"embd_pdrop\": 0.1,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"openai-gpt\",\n  \"n_ctx\": 512,\n  \"n_embd\": 768,\n  \"n_head\": 12,\n  \"n_layer\": 12,\n  \"n_positions\": 512,\n  \"n_special\": 0,\n  \"predict_special_tokens\": true,\n  \"resid_pdrop\": 0.1,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"task_specific_params\": {\n    \"text-generation\": {\n      \"do_sample\": true,\n      \"max_length\": 50\n    }\n  },\n  \"transformers_version\": \"4.45.1\",\n  \"vocab_size\": 40478\n}\n\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.json:   0%|          | 0.00/816k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "553de79dfaab4a3f988adacb66975b58"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "merges.txt:   0%|          | 0.00/458k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61403905747d4cb6bda35a9627f63032"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/1.27M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e395f6ad8014b6c91b52636fcff66d1"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "[INFO|tokenization_utils_base.py:2214] 2024-10-23 14:07:12,114 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--openai-community--openai-gpt/snapshots/1e0d4f3028acbffb47fe933cea64619c5ec1a002/vocab.json\n[INFO|tokenization_utils_base.py:2214] 2024-10-23 14:07:12,115 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--openai-community--openai-gpt/snapshots/1e0d4f3028acbffb47fe933cea64619c5ec1a002/merges.txt\n[INFO|tokenization_utils_base.py:2214] 2024-10-23 14:07:12,117 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--openai-community--openai-gpt/snapshots/1e0d4f3028acbffb47fe933cea64619c5ec1a002/tokenizer.json\n[INFO|tokenization_utils_base.py:2214] 2024-10-23 14:07:12,118 >> loading file added_tokens.json from cache at None\n[INFO|tokenization_utils_base.py:2214] 2024-10-23 14:07:12,119 >> loading file special_tokens_map.json from cache at None\n[INFO|tokenization_utils_base.py:2214] 2024-10-23 14:07:12,120 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--openai-community--openai-gpt/snapshots/1e0d4f3028acbffb47fe933cea64619c5ec1a002/tokenizer_config.json\n[INFO|configuration_utils.py:672] 2024-10-23 14:07:12,121 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--openai-community--openai-gpt/snapshots/1e0d4f3028acbffb47fe933cea64619c5ec1a002/config.json\n[INFO|configuration_utils.py:739] 2024-10-23 14:07:12,124 >> Model config OpenAIGPTConfig {\n  \"_name_or_path\": \"openai-community/openai-gpt\",\n  \"afn\": \"gelu\",\n  \"architectures\": [\n    \"OpenAIGPTLMHeadModel\"\n  ],\n  \"attn_pdrop\": 0.1,\n  \"embd_pdrop\": 0.1,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"openai-gpt\",\n  \"n_ctx\": 512,\n  \"n_embd\": 768,\n  \"n_head\": 12,\n  \"n_layer\": 12,\n  \"n_positions\": 512,\n  \"n_special\": 0,\n  \"predict_special_tokens\": true,\n  \"resid_pdrop\": 0.1,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"task_specific_params\": {\n    \"text-generation\": {\n      \"do_sample\": true,\n      \"max_length\": 50\n    }\n  },\n  \"transformers_version\": \"4.45.1\",\n  \"vocab_size\": 40478\n}\n\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/479M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b9cbb2430b3481d9ab6ae53e73a1342"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "[INFO|modeling_utils.py:3732] 2024-10-23 14:07:14,241 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--openai-community--openai-gpt/snapshots/1e0d4f3028acbffb47fe933cea64619c5ec1a002/model.safetensors\n[INFO|configuration_utils.py:1099] 2024-10-23 14:07:14,281 >> Generate config GenerationConfig {}\n\n[INFO|modeling_utils.py:4574] 2024-10-23 14:07:14,363 >> All model checkpoint weights were used when initializing OpenAIGPTLMHeadModel.\n\n[INFO|modeling_utils.py:4582] 2024-10-23 14:07:14,364 >> All the weights of OpenAIGPTLMHeadModel were initialized from the model checkpoint at openai-community/openai-gpt.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use OpenAIGPTLMHeadModel for predictions without further training.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/74.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "164d938393f5449db0e2695e287e765b"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "[INFO|configuration_utils.py:1054] 2024-10-23 14:07:14,551 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--openai-community--openai-gpt/snapshots/1e0d4f3028acbffb47fe933cea64619c5ec1a002/generation_config.json\n[INFO|configuration_utils.py:1099] 2024-10-23 14:07:14,552 >> Generate config GenerationConfig {}\n\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/4358 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea44bed0fe1945eca91d8adb967cf853"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3/cache-32a82fe4af55fb5f.arrow\n[WARNING|tokenization_utils_base.py:4092] 2024-10-23 14:07:15,069 >> Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/36718 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbaad39eab4049179a4c31642c239b2e"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3/cache-cc583239b6aa6505.arrow\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/3760 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2332ec87b510496ea6430f0fb755a573"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3/cache-2bcb757bbc28cd78.arrow\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/4358 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "833910866ef64cff852a26b1398c4ba3"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3/cache-94180eb137c8bd7e.arrow\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/36718 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41dd208feec54475ac7ca7908e0a4eea"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3/cache-0b7a9c2b31c919af.arrow\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/3760 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38e207d8e11340cfa90c50b2807a482d"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3/cache-e5e9136e48557ffa.arrow\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# train_dataset = lm_datasets[\"train\"]\n",
        "\n",
        "train_val_split = lm_datasets[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "train_dataset = train_val_split[\"train\"]\n",
        "\n",
        "eval_dataset = train_val_split[\"test\"]\n",
        "\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=default_data_collator\n",
        ")"
      ],
      "metadata": {
        "id": "EMSAVdpeEC00",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-23T14:07:25.666671Z",
          "iopub.execute_input": "2024-10-23T14:07:25.667069Z",
          "iopub.status.idle": "2024-10-23T14:07:26.164696Z",
          "shell.execute_reply.started": "2024-10-23T14:07:25.667025Z",
          "shell.execute_reply": "2024-10-23T14:07:26.163696Z"
        },
        "outputId": "6781bad1-cbd3-440a-9d49-0cec5243500f"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Caching indices mapping at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3/cache-d2d6999a00315909.arrow\nCaching indices mapping at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3/cache-fd01efde58090c7a.arrow\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "checkpoint = None\n",
        "\n",
        "last_checkpoint = get_last_checkpoint(training_args.output_dir)  # 만약 output_dir에 checkpoint가 남아있으면 이를 사용하고, 없으면 None이 return됩니다.\n",
        "\n",
        "if training_args.resume_from_checkpoint is not None:  # output_dir이 아닌 다른 위치에서의 checkpoint를 resume_from_checkpoint로 지정할 수 있습니다.\n",
        "\n",
        "    checkpoint = training_args.resume_from_checkpoint\n",
        "\n",
        "else:  # 아니면 last_checkpoint로 checkpoint를 지정합니다.\n",
        "\n",
        "    checkpoint = last_checkpoint\n",
        "\n",
        "\n",
        "eval_results = trainer.evaluate()\n",
        "wandb.log({\"eval_results\": eval_results})\n",
        "\n",
        "train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
        "\n",
        "\n",
        "trainer.save_model()\n",
        "\n",
        "\n",
        "train_metrics = train_result.metrics\n",
        "\n",
        "eval_metrics = eval_results\n",
        "\n",
        "\n",
        "\n",
        "trainer.log_metrics(\"eval\", eval_metrics)\n",
        "\n",
        "trainer.save_metrics(\"eval\", eval_metrics)\n",
        "\n",
        "\n",
        "\n",
        "trainer.log_metrics(\"train\", train_metrics)\n",
        "\n",
        "trainer.save_metrics(\"train\", train_metrics)\n",
        "\n",
        "trainer.save_state()\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "233f296b9db444978e0962c8cc70836c"
          ]
        },
        "id": "6aonV0kl7E_N",
        "outputId": "c40b345f-b52e-4f56-e7ad-6229b625bc25",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-23T14:07:26.165901Z",
          "iopub.execute_input": "2024-10-23T14:07:26.166235Z",
          "iopub.status.idle": "2024-10-23T14:22:05.987701Z",
          "shell.execute_reply.started": "2024-10-23T14:07:26.166202Z",
          "shell.execute_reply": "2024-10-23T14:22:05.986967Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "[INFO|trainer.py:4021] 2024-10-23 14:07:27,209 >> \n***** Running Evaluation *****\n[INFO|trainer.py:4023] 2024-10-23 14:07:27,211 >>   Num examples = 917\n[INFO|trainer.py:4026] 2024-10-23 14:07:27,212 >>   Batch size = 8\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='115' max='115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [115/115 00:23]\n    </div>\n    "
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "[INFO|integration_utils.py:811] 2024-10-23 14:07:51,912 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n[INFO|trainer.py:2243] 2024-10-23 14:07:52,326 >> ***** Running training *****\n[INFO|trainer.py:2244] 2024-10-23 14:07:52,327 >>   Num examples = 3,664\n[INFO|trainer.py:2245] 2024-10-23 14:07:52,329 >>   Num Epochs = 3\n[INFO|trainer.py:2246] 2024-10-23 14:07:52,330 >>   Instantaneous batch size per device = 8\n[INFO|trainer.py:2249] 2024-10-23 14:07:52,332 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n[INFO|trainer.py:2250] 2024-10-23 14:07:52,333 >>   Gradient Accumulation steps = 1\n[INFO|trainer.py:2251] 2024-10-23 14:07:52,334 >>   Total optimization steps = 1,374\n[INFO|trainer.py:2252] 2024-10-23 14:07:52,336 >>   Number of trainable parameters = 116,534,784\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='1374' max='1374' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1374/1374 14:09, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>4.075800</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>3.931100</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>3.888300</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>3.861000</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>3.747800</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>3.645900</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>3.630600</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>3.637500</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>3.634300</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>3.523400</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>3.517100</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>3.519000</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>3.509100</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "[INFO|trainer.py:3705] 2024-10-23 14:12:59,379 >> Saving model checkpoint to ./output/checkpoint-500\n[INFO|configuration_utils.py:407] 2024-10-23 14:12:59,382 >> Configuration saved in ./output/checkpoint-500/config.json\n[INFO|configuration_utils.py:868] 2024-10-23 14:12:59,384 >> Configuration saved in ./output/checkpoint-500/generation_config.json\n[INFO|modeling_utils.py:2836] 2024-10-23 14:13:00,389 >> Model weights saved in ./output/checkpoint-500/model.safetensors\n[INFO|tokenization_utils_base.py:2649] 2024-10-23 14:13:00,391 >> tokenizer config file saved in ./output/checkpoint-500/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2658] 2024-10-23 14:13:00,393 >> Special tokens file saved in ./output/checkpoint-500/special_tokens_map.json\n[INFO|trainer.py:3705] 2024-10-23 14:18:08,466 >> Saving model checkpoint to ./output/checkpoint-1000\n[INFO|configuration_utils.py:407] 2024-10-23 14:18:08,470 >> Configuration saved in ./output/checkpoint-1000/config.json\n[INFO|configuration_utils.py:868] 2024-10-23 14:18:08,472 >> Configuration saved in ./output/checkpoint-1000/generation_config.json\n[INFO|modeling_utils.py:2836] 2024-10-23 14:18:09,469 >> Model weights saved in ./output/checkpoint-1000/model.safetensors\n[INFO|tokenization_utils_base.py:2649] 2024-10-23 14:18:09,471 >> tokenizer config file saved in ./output/checkpoint-1000/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2658] 2024-10-23 14:18:09,473 >> Special tokens file saved in ./output/checkpoint-1000/special_tokens_map.json\n[INFO|trainer.py:3797] 2024-10-23 14:18:10,823 >> Deleting older checkpoint [output/checkpoint-500] due to args.save_total_limit\n[INFO|trainer.py:3705] 2024-10-23 14:22:00,394 >> Saving model checkpoint to ./output/checkpoint-1374\n[INFO|configuration_utils.py:407] 2024-10-23 14:22:00,399 >> Configuration saved in ./output/checkpoint-1374/config.json\n[INFO|configuration_utils.py:868] 2024-10-23 14:22:00,400 >> Configuration saved in ./output/checkpoint-1374/generation_config.json\n[INFO|modeling_utils.py:2836] 2024-10-23 14:22:01,399 >> Model weights saved in ./output/checkpoint-1374/model.safetensors\n[INFO|tokenization_utils_base.py:2649] 2024-10-23 14:22:01,402 >> tokenizer config file saved in ./output/checkpoint-1374/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2658] 2024-10-23 14:22:01,403 >> Special tokens file saved in ./output/checkpoint-1374/special_tokens_map.json\n[INFO|trainer.py:3797] 2024-10-23 14:22:03,091 >> Deleting older checkpoint [output/checkpoint-1000] due to args.save_total_limit\n[INFO|trainer.py:2505] 2024-10-23 14:22:03,280 >> \n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n[INFO|trainer.py:3705] 2024-10-23 14:22:03,288 >> Saving model checkpoint to ./output\n[INFO|configuration_utils.py:407] 2024-10-23 14:22:03,291 >> Configuration saved in ./output/config.json\n[INFO|configuration_utils.py:868] 2024-10-23 14:22:03,293 >> Configuration saved in ./output/generation_config.json\n[INFO|modeling_utils.py:2836] 2024-10-23 14:22:04,298 >> Model weights saved in ./output/model.safetensors\n[INFO|tokenization_utils_base.py:2649] 2024-10-23 14:22:04,301 >> tokenizer config file saved in ./output/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2658] 2024-10-23 14:22:04,302 >> Special tokens file saved in ./output/special_tokens_map.json\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "***** eval metrics *****\n  eval_loss                   =     4.3906\n  eval_model_preparation_time =      0.006\n  eval_runtime                = 0:00:25.72\n  eval_samples_per_second     =      35.64\n  eval_steps_per_second       =       4.47\n***** train metrics *****\n  epoch                    =        3.0\n  total_flos               =  2674823GF\n  train_loss               =     3.6916\n  train_runtime            = 0:14:10.94\n  train_samples_per_second =     12.917\n  train_steps_per_second   =      1.615\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(Label(value='0.038 MB of 0.038 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "233f296b9db444978e0962c8cc70836c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/model_preparation_time</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▃▄▄▅▅▆▆▇██</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>train/grad_norm</td><td>▅█▄▂▁▂▄▁▄▃▂▃▁</td></tr><tr><td>train/learning_rate</td><td>█▇▇▆▆▅▅▄▃▃▂▂▁</td></tr><tr><td>train/loss</td><td>█▆▆▅▄▃▃▃▃▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>4.39061</td></tr><tr><td>eval/model_preparation_time</td><td>0.006</td></tr><tr><td>eval/runtime</td><td>25.7298</td></tr><tr><td>eval/samples_per_second</td><td>35.64</td></tr><tr><td>eval/steps_per_second</td><td>4.47</td></tr><tr><td>total_flos</td><td>2872070148980736.0</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>1374</td></tr><tr><td>train/grad_norm</td><td>1.80693</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>3.5091</td></tr><tr><td>train_loss</td><td>3.69157</td></tr><tr><td>train_runtime</td><td>850.944</td></tr><tr><td>train_samples_per_second</td><td>12.917</td></tr><tr><td>train_steps_per_second</td><td>1.615</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">sparkling-gorge-2</strong> at: <a href='https://wandb.ai/csn2506-diem/Chapter4-1-basic/runs/2oesg8d4' target=\"_blank\">https://wandb.ai/csn2506-diem/Chapter4-1-basic/runs/2oesg8d4</a><br/> View project at: <a href='https://wandb.ai/csn2506-diem/Chapter4-1-basic' target=\"_blank\">https://wandb.ai/csn2506-diem/Chapter4-1-basic</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20241023_140702-2oesg8d4/logs</code>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    }
  ]
}