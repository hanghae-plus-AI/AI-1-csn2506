{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5606687684e64c9a944291a636ec0976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_791c72e1fdb84b97bf66cc820dff9077",
              "IPY_MODEL_5f6a104d1828430986a70f0da90eb707",
              "IPY_MODEL_22159a68e8624cc4820e688caeda837f"
            ],
            "layout": "IPY_MODEL_ed064bbbee7b429fb03810ea834cd030"
          }
        },
        "791c72e1fdb84b97bf66cc820dff9077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f44e14faa894ed780575b57d5f74579",
            "placeholder": "​",
            "style": "IPY_MODEL_8a4b4608fedc44259a3c023e0c4847a9",
            "value": "Map: 100%"
          }
        },
        "5f6a104d1828430986a70f0da90eb707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b32c67658cc4e42ba01ab5c49613ca0",
            "max": 36718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc8275a47cc5467c9ad3c24e02f9face",
            "value": 36718
          }
        },
        "22159a68e8624cc4820e688caeda837f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a976a77618b479ba1c98af21632a760",
            "placeholder": "​",
            "style": "IPY_MODEL_8cc5ac71ce2e41938bf2f0899da3859a",
            "value": " 36718/36718 [00:12&lt;00:00, 5021.80 examples/s]"
          }
        },
        "ed064bbbee7b429fb03810ea834cd030": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f44e14faa894ed780575b57d5f74579": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a4b4608fedc44259a3c023e0c4847a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b32c67658cc4e42ba01ab5c49613ca0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc8275a47cc5467c9ad3c24e02f9face": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a976a77618b479ba1c98af21632a760": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cc5ac71ce2e41938bf2f0899da3859a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b08bc56d51448fbb8d7c67afa1bad5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8fb78e66c0f14593b4d15574f5e4a83e",
              "IPY_MODEL_44a7c34cc3e141518716f7718b0256e8",
              "IPY_MODEL_a8d2f3c18c3b48c5aad33e2baea4581c"
            ],
            "layout": "IPY_MODEL_11bc7a35c16847e9998eedbd934c0932"
          }
        },
        "8fb78e66c0f14593b4d15574f5e4a83e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5faac1cbb2454cb8b738f1f5c1bd7e8b",
            "placeholder": "​",
            "style": "IPY_MODEL_a9a1247f7e514fffbac602a486f06327",
            "value": "Map: 100%"
          }
        },
        "44a7c34cc3e141518716f7718b0256e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9a0b3de43cf447abfb9582da9435c0c",
            "max": 36718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_783ad3ed6c3e4ad8ad02f3c0cf03b0ab",
            "value": 36718
          }
        },
        "a8d2f3c18c3b48c5aad33e2baea4581c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cc7017c6adb4424aca05065a733d3c5",
            "placeholder": "​",
            "style": "IPY_MODEL_91baf3d72fe44bfdb193769eb476eb73",
            "value": " 36718/36718 [00:04&lt;00:00, 6716.26 examples/s]"
          }
        },
        "11bc7a35c16847e9998eedbd934c0932": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5faac1cbb2454cb8b738f1f5c1bd7e8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9a1247f7e514fffbac602a486f06327": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9a0b3de43cf447abfb9582da9435c0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "783ad3ed6c3e4ad8ad02f3c0cf03b0ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6cc7017c6adb4424aca05065a733d3c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91baf3d72fe44bfdb193769eb476eb73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30787,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanghae-plus-AI/AI-1-csn2506/blob/main/Chapter4_1_%EA%B8%B0%EB%B3%B8%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-1- 기본과제\n",
        "\n",
        "## Validation data를 포함하여 Fine-tuning 해보기"
      ],
      "metadata": {
        "id": "3EEKHAt9Ksyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTIjd9RlI-o-",
        "outputId": "01c2b3e4-3aa3-4e4f-d48f-586429099ebd",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-23T14:50:05.165513Z",
          "iopub.execute_input": "2024-10-23T14:50:05.165995Z",
          "iopub.status.idle": "2024-10-23T14:50:16.892114Z",
          "shell.execute_reply.started": "2024-10-23T14:50:05.165911Z",
          "shell.execute_reply": "2024-10-23T14:50:16.890925Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import sys\n",
        "\n",
        "import math\n",
        "\n",
        "import torch\n",
        "\n",
        "import wandb\n",
        "\n",
        "import logging\n",
        "\n",
        "import datasets\n",
        "\n",
        "import argparse\n",
        "\n",
        "import evaluate\n",
        "\n",
        "import transformers\n",
        "\n",
        "\n",
        "\n",
        "from typing import Optional\n",
        "\n",
        "from itertools import chain\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "\n",
        "\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "from transformers import (\n",
        "\n",
        "    AutoConfig,\n",
        "\n",
        "    AutoModelForCausalLM,\n",
        "\n",
        "    AutoTokenizer,\n",
        "\n",
        "    HfArgumentParser,\n",
        "\n",
        "    Trainer,\n",
        "\n",
        "    TrainingArguments,\n",
        "\n",
        "    default_data_collator\n",
        "\n",
        ")\n",
        "\n",
        "from transformers.trainer_utils import get_last_checkpoint"
      ],
      "metadata": {
        "id": "OfVbcKWXKEiA",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-23T14:50:16.89426Z",
          "iopub.execute_input": "2024-10-23T14:50:16.894593Z",
          "iopub.status.idle": "2024-10-23T14:50:25.132307Z",
          "shell.execute_reply.started": "2024-10-23T14:50:16.89456Z",
          "shell.execute_reply": "2024-10-23T14:50:25.131488Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project='Chapter4-1-basic')\n",
        "\n",
        "wandb.run.name = 'gpts-finetuning'"
      ],
      "metadata": {
        "id": "kfQrVZS9KNX7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215,
          "referenced_widgets": [
            "08000dcf02b54e1bbe9648ff83cd30ee"
          ]
        },
        "outputId": "03ccf906-60b3-45a2-ce8b-aab1ca4053ec",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-23T14:50:25.133292Z",
          "iopub.execute_input": "2024-10-23T14:50:25.133858Z",
          "iopub.status.idle": "2024-10-23T14:50:29.987788Z",
          "shell.execute_reply.started": "2024-10-23T14:50:25.133825Z",
          "shell.execute_reply": "2024-10-23T14:50:29.987037Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcsn2506\u001b[0m (\u001b[33mcsn2506-diem\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111369234444434, max=1.0)…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08000dcf02b54e1bbe9648ff83cd30ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.18.3"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20241023_145026-7484mlih</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/csn2506-diem/Chapter4-1-basic/runs/7484mlih' target=\"_blank\">golden-thunder-4</a></strong> to <a href='https://wandb.ai/csn2506-diem/Chapter4-1-basic' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/csn2506-diem/Chapter4-1-basic' target=\"_blank\">https://wandb.ai/csn2506-diem/Chapter4-1-basic</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/csn2506-diem/Chapter4-1-basic/runs/7484mlih' target=\"_blank\">https://wandb.ai/csn2506-diem/Chapter4-1-basic/runs/7484mlih</a>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "\n",
        "class Arguments:\n",
        "\n",
        "    model_name_or_path: Optional[str] = field(default=None)  # HuggingFace hub에서 pre-trained 모델로 사용할 모델의 이름\n",
        "\n",
        "    torch_dtype: Optional[str] = field(default=None, metadata={'choices': ['auto', 'bfloat16', 'float16', 'float32']})  # 우리 모델의 precision(data type이라고 이해하시면 됩니다)\n",
        "\n",
        "\n",
        "\n",
        "    dataset_name: Optional[str] = field(default=None)  # Fine-tuning으로 사용할 huggingface hub에서의 dataset 이름\n",
        "\n",
        "    dataset_config_name: Optional[str] = field(default=None)  # Fine-tuning으로 사용할 huggingface hub에서의 dataset configuration\n",
        "\n",
        "    block_size: int = field(default=1024)  # Fine-tuning에 사용할 input text의 길이\n",
        "\n",
        "    num_workers: Optional[int] = field(default=None)  # Data를 업로드하거나 전처리할 때 사용할 worker 숫자\n",
        "\n",
        "\n",
        "\n",
        "import sys\n",
        "\n",
        "sys.argv = [\n",
        "\n",
        "    sys.argv[0],\n",
        "\n",
        "    \"--output_dir\", \"./output\",\n",
        "\n",
        "    \"--per_device_train_batch_size\", \"8\",\n",
        "\n",
        "    \"--per_device_eval_batch_size\", \"8\",\n",
        "\n",
        "    \"--num_train_epochs\", \"3\",\n",
        "\n",
        "    \"--eval_strategy\", \"epoch\",\n",
        "\n",
        "    \"--logging_dir\", \"./logs\",\n",
        "\n",
        "    \"--dataset_name\", \"wikitext\",\n",
        "\n",
        "    \"--model_name_or_path\", \"openai-community/openai-gpt\",\n",
        "\n",
        "    \"--dataset_config_name\", \"wikitext-2-raw-v1\",\n",
        "\n",
        "    \"--do_train\",\n",
        "\n",
        "    \"--save_total_limit\", \"1\",\n",
        "\n",
        "    \"--logging_steps\", \"100\",\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "parser = HfArgumentParser((Arguments, TrainingArguments))\n",
        "\n",
        "args, training_args = parser.parse_args_into_dataclasses()\n",
        "\n",
        "\n",
        "\n",
        "logger = logging.getLogger()\n",
        "\n",
        "\n",
        "\n",
        "logging.basicConfig(\n",
        "\n",
        "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
        "\n",
        "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "\n",
        "    handlers=[logging.StreamHandler(sys.stdout)],\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "if training_args.should_log:\n",
        "\n",
        "    transformers.utils.logging.set_verbosity_info()  # log level을 INFO로 변경\n",
        "\n",
        "\n",
        "\n",
        "log_level = training_args.get_process_log_level()\n",
        "\n",
        "logger.setLevel(log_level)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 우리가 가지고 있는 logger와 HuggingFace의 logger의 log level 설정\n",
        "\n",
        "logger.setLevel(log_level)\n",
        "\n",
        "datasets.utils.logging.set_verbosity(log_level)\n",
        "\n",
        "transformers.utils.logging.set_verbosity(log_level)\n",
        "\n",
        "\n",
        "\n",
        "# 기타 HuggingFace logger option들을 설정\n",
        "\n",
        "transformers.utils.logging.enable_default_handler()\n",
        "\n",
        "transformers.utils.logging.enable_explicit_format()\n",
        "\n",
        "\n",
        "\n",
        "logger.info(f\"Training/evaluation parameters {training_args}\")"
      ],
      "metadata": {
        "id": "UHZ--LQcKO7C",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-23T14:50:29.990359Z",
          "iopub.execute_input": "2024-10-23T14:50:29.991024Z",
          "iopub.status.idle": "2024-10-23T14:50:30.08582Z",
          "shell.execute_reply.started": "2024-10-23T14:50:29.990953Z",
          "shell.execute_reply": "2024-10-23T14:50:30.084813Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터셋 로드"
      ],
      "metadata": {
        "id": "BI_pR0sd7sWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "raw_datasets = load_dataset(\n",
        "\n",
        "    args.dataset_name,\n",
        "\n",
        "    args.dataset_config_name\n",
        "\n",
        ")\n"
      ],
      "metadata": {
        "id": "4a5IzL1VKStS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83555595-5570-4845-a831-8a3c5fcde80e",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-23T14:50:30.087Z",
          "iopub.execute_input": "2024-10-23T14:50:30.087293Z",
          "iopub.status.idle": "2024-10-23T14:50:38.665504Z",
          "shell.execute_reply.started": "2024-10-23T14:50:30.087261Z",
          "shell.execute_reply": "2024-10-23T14:50:38.664701Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Overwrite dataset info from restored data version if exists.\nLoading Dataset info from /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3\nFound cached dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3)\nLoading Dataset info from /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "config = AutoConfig.from_pretrained(args.model_name_or_path)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(args.model_name_or_path)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "\n",
        "    args.model_name_or_path,\n",
        "\n",
        "    config=config,\n",
        "\n",
        "    torch_dtype=args.torch_dtype\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "tokenizer.chat_template = \"{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}\"\n",
        "\n",
        "\n",
        "\n",
        "embedding_size = model.get_input_embeddings().weight.shape[0]\n",
        "\n",
        "if len(tokenizer) > embedding_size:\n",
        "\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "\n",
        "\n",
        "column_names = list(raw_datasets[\"train\"].features)\n",
        "\n",
        "text_column_name = \"text\" if \"text\" in column_names else column_names[0]\n",
        "\n",
        "\n",
        "\n",
        "def tokenize_function(examples):\n",
        "\n",
        "    output = tokenizer(examples[text_column_name])\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "with training_args.main_process_first(desc=\"dataset map tokenization\"):\n",
        "\n",
        "    tokenized_datasets = raw_datasets.map(\n",
        "\n",
        "        tokenize_function,\n",
        "\n",
        "        batched=True,\n",
        "\n",
        "        num_proc=args.num_workers,\n",
        "\n",
        "        remove_columns=column_names\n",
        "\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "max_pos_embeddings = config.max_position_embeddings if hasattr(config, \"max_position_embeddings\") else 1024\n",
        "\n",
        "block_size = args.block_size if tokenizer.model_max_length is None else min(args.block_size, tokenizer.model_max_length)\n",
        "\n",
        "\n",
        "\n",
        "def group_texts(examples):\n",
        "\n",
        "    # 주어진 text들을 모두 concat 해줍니다.\n",
        "\n",
        "    # 예를 들어 examples = {'train': [['Hello!'], ['Yes, that is great!']]}이면 결과물은 {'train': ['Hello! Yes, that is great!']}가 됩니다.\n",
        "\n",
        "    concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n",
        "\n",
        "\n",
        "\n",
        "    # 전체 길이를 측정합니다.\n",
        "\n",
        "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
        "\n",
        "    total_length = (total_length // block_size) * block_size\n",
        "\n",
        "\n",
        "\n",
        "    # block_size로 text를 쪼갭니다.\n",
        "\n",
        "    # 예를 들어 block_size=3일 때 {'train': ['Hello! Yes, that is great!']}는\n",
        "\n",
        "    # {'train': ['Hel', 'lo!', ' Ye', 's, ', 'tha', ...]}가 됩니다.\n",
        "\n",
        "    result = {\n",
        "\n",
        "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
        "\n",
        "        for k, t in concatenated_examples.items()\n",
        "\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "    # Next token prediction이니 label은 자기 자신으로 설정합니다.\n",
        "\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "with training_args.main_process_first(desc=\"grouping texts together\"):\n",
        "\n",
        "    lm_datasets = tokenized_datasets.map(\n",
        "\n",
        "        group_texts,\n",
        "\n",
        "        batched=True,\n",
        "\n",
        "        num_proc=args.num_workers\n",
        "\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5606687684e64c9a944291a636ec0976",
            "791c72e1fdb84b97bf66cc820dff9077",
            "5f6a104d1828430986a70f0da90eb707",
            "22159a68e8624cc4820e688caeda837f",
            "ed064bbbee7b429fb03810ea834cd030",
            "5f44e14faa894ed780575b57d5f74579",
            "8a4b4608fedc44259a3c023e0c4847a9",
            "8b32c67658cc4e42ba01ab5c49613ca0",
            "cc8275a47cc5467c9ad3c24e02f9face",
            "2a976a77618b479ba1c98af21632a760",
            "8cc5ac71ce2e41938bf2f0899da3859a",
            "5b08bc56d51448fbb8d7c67afa1bad5f",
            "8fb78e66c0f14593b4d15574f5e4a83e",
            "44a7c34cc3e141518716f7718b0256e8",
            "a8d2f3c18c3b48c5aad33e2baea4581c",
            "11bc7a35c16847e9998eedbd934c0932",
            "5faac1cbb2454cb8b738f1f5c1bd7e8b",
            "a9a1247f7e514fffbac602a486f06327",
            "f9a0b3de43cf447abfb9582da9435c0c",
            "783ad3ed6c3e4ad8ad02f3c0cf03b0ab",
            "6cc7017c6adb4424aca05065a733d3c5",
            "91baf3d72fe44bfdb193769eb476eb73",
            "63ea10f2fa154adb8e8f13489b3f2bb2",
            "cfc758a94a934e07a07a153dba51d511"
          ]
        },
        "id": "w3hS9bH70cvl",
        "outputId": "13fed5c7-8eae-472a-ea66-c38481086136",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-23T14:50:38.666712Z",
          "iopub.execute_input": "2024-10-23T14:50:38.667023Z",
          "iopub.status.idle": "2024-10-23T14:50:49.257609Z",
          "shell.execute_reply.started": "2024-10-23T14:50:38.666968Z",
          "shell.execute_reply": "2024-10-23T14:50:49.256724Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "[INFO|configuration_utils.py:672] 2024-10-23 14:50:38,933 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--openai-community--openai-gpt/snapshots/1e0d4f3028acbffb47fe933cea64619c5ec1a002/config.json\n[INFO|configuration_utils.py:739] 2024-10-23 14:50:38,937 >> Model config OpenAIGPTConfig {\n  \"_name_or_path\": \"openai-community/openai-gpt\",\n  \"afn\": \"gelu\",\n  \"architectures\": [\n    \"OpenAIGPTLMHeadModel\"\n  ],\n  \"attn_pdrop\": 0.1,\n  \"embd_pdrop\": 0.1,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"openai-gpt\",\n  \"n_ctx\": 512,\n  \"n_embd\": 768,\n  \"n_head\": 12,\n  \"n_layer\": 12,\n  \"n_positions\": 512,\n  \"n_special\": 0,\n  \"predict_special_tokens\": true,\n  \"resid_pdrop\": 0.1,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"task_specific_params\": {\n    \"text-generation\": {\n      \"do_sample\": true,\n      \"max_length\": 50\n    }\n  },\n  \"transformers_version\": \"4.45.1\",\n  \"vocab_size\": 40478\n}\n\n[INFO|configuration_utils.py:672] 2024-10-23 14:50:39,132 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--openai-community--openai-gpt/snapshots/1e0d4f3028acbffb47fe933cea64619c5ec1a002/config.json\n[INFO|configuration_utils.py:739] 2024-10-23 14:50:39,135 >> Model config OpenAIGPTConfig {\n  \"_name_or_path\": \"openai-community/openai-gpt\",\n  \"afn\": \"gelu\",\n  \"architectures\": [\n    \"OpenAIGPTLMHeadModel\"\n  ],\n  \"attn_pdrop\": 0.1,\n  \"embd_pdrop\": 0.1,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"openai-gpt\",\n  \"n_ctx\": 512,\n  \"n_embd\": 768,\n  \"n_head\": 12,\n  \"n_layer\": 12,\n  \"n_positions\": 512,\n  \"n_special\": 0,\n  \"predict_special_tokens\": true,\n  \"resid_pdrop\": 0.1,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"task_specific_params\": {\n    \"text-generation\": {\n      \"do_sample\": true,\n      \"max_length\": 50\n    }\n  },\n  \"transformers_version\": \"4.45.1\",\n  \"vocab_size\": 40478\n}\n\n[INFO|tokenization_utils_base.py:2214] 2024-10-23 14:50:39,139 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--openai-community--openai-gpt/snapshots/1e0d4f3028acbffb47fe933cea64619c5ec1a002/vocab.json\n[INFO|tokenization_utils_base.py:2214] 2024-10-23 14:50:39,139 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--openai-community--openai-gpt/snapshots/1e0d4f3028acbffb47fe933cea64619c5ec1a002/merges.txt\n[INFO|tokenization_utils_base.py:2214] 2024-10-23 14:50:39,140 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--openai-community--openai-gpt/snapshots/1e0d4f3028acbffb47fe933cea64619c5ec1a002/tokenizer.json\n[INFO|tokenization_utils_base.py:2214] 2024-10-23 14:50:39,141 >> loading file added_tokens.json from cache at None\n[INFO|tokenization_utils_base.py:2214] 2024-10-23 14:50:39,143 >> loading file special_tokens_map.json from cache at None\n[INFO|tokenization_utils_base.py:2214] 2024-10-23 14:50:39,144 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--openai-community--openai-gpt/snapshots/1e0d4f3028acbffb47fe933cea64619c5ec1a002/tokenizer_config.json\n[INFO|configuration_utils.py:672] 2024-10-23 14:50:39,145 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--openai-community--openai-gpt/snapshots/1e0d4f3028acbffb47fe933cea64619c5ec1a002/config.json\n[INFO|configuration_utils.py:739] 2024-10-23 14:50:39,148 >> Model config OpenAIGPTConfig {\n  \"_name_or_path\": \"openai-community/openai-gpt\",\n  \"afn\": \"gelu\",\n  \"architectures\": [\n    \"OpenAIGPTLMHeadModel\"\n  ],\n  \"attn_pdrop\": 0.1,\n  \"embd_pdrop\": 0.1,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"openai-gpt\",\n  \"n_ctx\": 512,\n  \"n_embd\": 768,\n  \"n_head\": 12,\n  \"n_layer\": 12,\n  \"n_positions\": 512,\n  \"n_special\": 0,\n  \"predict_special_tokens\": true,\n  \"resid_pdrop\": 0.1,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"task_specific_params\": {\n    \"text-generation\": {\n      \"do_sample\": true,\n      \"max_length\": 50\n    }\n  },\n  \"transformers_version\": \"4.45.1\",\n  \"vocab_size\": 40478\n}\n\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n[INFO|modeling_utils.py:3732] 2024-10-23 14:50:39,318 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--openai-community--openai-gpt/snapshots/1e0d4f3028acbffb47fe933cea64619c5ec1a002/model.safetensors\n[INFO|configuration_utils.py:1099] 2024-10-23 14:50:39,328 >> Generate config GenerationConfig {}\n\n[INFO|modeling_utils.py:4574] 2024-10-23 14:50:39,381 >> All model checkpoint weights were used when initializing OpenAIGPTLMHeadModel.\n\n[INFO|modeling_utils.py:4582] 2024-10-23 14:50:39,382 >> All the weights of OpenAIGPTLMHeadModel were initialized from the model checkpoint at openai-community/openai-gpt.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use OpenAIGPTLMHeadModel for predictions without further training.\n[INFO|configuration_utils.py:1054] 2024-10-23 14:50:39,580 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--openai-community--openai-gpt/snapshots/1e0d4f3028acbffb47fe933cea64619c5ec1a002/generation_config.json\n[INFO|configuration_utils.py:1099] 2024-10-23 14:50:39,582 >> Generate config GenerationConfig {}\n\nLoading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3/cache-32a82fe4af55fb5f.arrow\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/36718 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63ea10f2fa154adb8e8f13489b3f2bb2"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3/cache-5ddcb20e18cb16c2.arrow\n[WARNING|tokenization_utils_base.py:4092] 2024-10-23 14:50:39,909 >> Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\nLoading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3/cache-2bcb757bbc28cd78.arrow\nLoading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3/cache-94180eb137c8bd7e.arrow\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/36718 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfc758a94a934e07a07a153dba51d511"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3/cache-8cb9e97d0ee24198.arrow\nLoading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3/cache-e5e9136e48557ffa.arrow\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# train_dataset = lm_datasets[\"train\"]\n",
        "\n",
        "train_val_split = lm_datasets[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "train_dataset = train_val_split[\"train\"]\n",
        "\n",
        "eval_dataset = train_val_split[\"test\"]\n",
        "\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=default_data_collator\n",
        ")"
      ],
      "metadata": {
        "id": "EMSAVdpeEC00",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-23T14:50:49.258761Z",
          "iopub.execute_input": "2024-10-23T14:50:49.259083Z",
          "iopub.status.idle": "2024-10-23T14:50:49.587496Z",
          "shell.execute_reply.started": "2024-10-23T14:50:49.25905Z",
          "shell.execute_reply": "2024-10-23T14:50:49.586466Z"
        },
        "outputId": "b4984790-0dd0-4e3e-9b80-2c7027078bb7"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Caching indices mapping at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3/cache-1dad48245bfc5c33.arrow\nCaching indices mapping at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3/cache-9ece1423888cb2b6.arrow\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "checkpoint = None\n",
        "\n",
        "last_checkpoint = get_last_checkpoint(training_args.output_dir)  # 만약 output_dir에 checkpoint가 남아있으면 이를 사용하고, 없으면 None이 return됩니다.\n",
        "\n",
        "if training_args.resume_from_checkpoint is not None:  # output_dir이 아닌 다른 위치에서의 checkpoint를 resume_from_checkpoint로 지정할 수 있습니다.\n",
        "\n",
        "    checkpoint = training_args.resume_from_checkpoint\n",
        "\n",
        "else:  # 아니면 last_checkpoint로 checkpoint를 지정합니다.\n",
        "\n",
        "    checkpoint = last_checkpoint\n",
        "\n",
        "\n",
        "eval_results = trainer.evaluate()\n",
        "# wandb.log({\"eval_results\": eval_results})\n",
        "\n",
        "train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
        "\n",
        "\n",
        "trainer.save_model()\n",
        "\n",
        "\n",
        "train_metrics = train_result.metrics\n",
        "\n",
        "eval_metrics = eval_results\n",
        "\n",
        "\n",
        "\n",
        "trainer.log_metrics(\"eval\", eval_metrics)\n",
        "\n",
        "trainer.save_metrics(\"eval\", eval_metrics)\n",
        "\n",
        "\n",
        "\n",
        "trainer.log_metrics(\"train\", train_metrics)\n",
        "\n",
        "trainer.save_metrics(\"train\", train_metrics)\n",
        "\n",
        "trainer.save_state()\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fbe37417294d420bbcbc9dd04fa0cc5a"
          ]
        },
        "id": "6aonV0kl7E_N",
        "outputId": "c40b345f-b52e-4f56-e7ad-6229b625bc25",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-10-23T14:50:49.58884Z",
          "iopub.execute_input": "2024-10-23T14:50:49.589278Z",
          "iopub.status.idle": "2024-10-23T15:06:43.057263Z",
          "shell.execute_reply.started": "2024-10-23T14:50:49.589234Z",
          "shell.execute_reply": "2024-10-23T15:06:43.056304Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "[INFO|trainer.py:4021] 2024-10-23 14:50:50,190 >> \n***** Running Evaluation *****\n[INFO|trainer.py:4023] 2024-10-23 14:50:50,192 >>   Num examples = 917\n[INFO|trainer.py:4026] 2024-10-23 14:50:50,193 >>   Batch size = 8\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='230' max='115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [115/115 05:29]\n    </div>\n    "
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "[INFO|integration_utils.py:811] 2024-10-23 14:51:14,704 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n[INFO|trainer.py:2243] 2024-10-23 14:51:15,107 >> ***** Running training *****\n[INFO|trainer.py:2244] 2024-10-23 14:51:15,109 >>   Num examples = 3,664\n[INFO|trainer.py:2245] 2024-10-23 14:51:15,110 >>   Num Epochs = 3\n[INFO|trainer.py:2246] 2024-10-23 14:51:15,111 >>   Instantaneous batch size per device = 8\n[INFO|trainer.py:2249] 2024-10-23 14:51:15,112 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n[INFO|trainer.py:2250] 2024-10-23 14:51:15,113 >>   Gradient Accumulation steps = 1\n[INFO|trainer.py:2251] 2024-10-23 14:51:15,114 >>   Total optimization steps = 1,374\n[INFO|trainer.py:2252] 2024-10-23 14:51:15,116 >>   Number of trainable parameters = 116,534,784\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='1374' max='1374' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1374/1374 15:23, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Model Preparation Time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>3.861000</td>\n      <td>3.691715</td>\n      <td>0.003800</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3.634300</td>\n      <td>3.629312</td>\n      <td>0.003800</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3.509100</td>\n      <td>3.615669</td>\n      <td>0.003800</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "[INFO|trainer.py:4021] 2024-10-23 14:55:56,265 >> \n***** Running Evaluation *****\n[INFO|trainer.py:4023] 2024-10-23 14:55:56,266 >>   Num examples = 917\n[INFO|trainer.py:4026] 2024-10-23 14:55:56,267 >>   Batch size = 8\n[INFO|trainer.py:3705] 2024-10-23 14:56:46,347 >> Saving model checkpoint to ./output/checkpoint-500\n[INFO|configuration_utils.py:407] 2024-10-23 14:56:46,351 >> Configuration saved in ./output/checkpoint-500/config.json\n[INFO|configuration_utils.py:868] 2024-10-23 14:56:46,353 >> Configuration saved in ./output/checkpoint-500/generation_config.json\n[INFO|modeling_utils.py:2836] 2024-10-23 14:56:47,365 >> Model weights saved in ./output/checkpoint-500/model.safetensors\n[INFO|tokenization_utils_base.py:2649] 2024-10-23 14:56:47,367 >> tokenizer config file saved in ./output/checkpoint-500/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2658] 2024-10-23 14:56:47,369 >> Special tokens file saved in ./output/checkpoint-500/special_tokens_map.json\n[INFO|trainer.py:4021] 2024-10-23 15:01:04,022 >> \n***** Running Evaluation *****\n[INFO|trainer.py:4023] 2024-10-23 15:01:04,023 >>   Num examples = 917\n[INFO|trainer.py:4026] 2024-10-23 15:01:04,024 >>   Batch size = 8\n[INFO|trainer.py:3705] 2024-10-23 15:02:19,866 >> Saving model checkpoint to ./output/checkpoint-1000\n[INFO|configuration_utils.py:407] 2024-10-23 15:02:19,870 >> Configuration saved in ./output/checkpoint-1000/config.json\n[INFO|configuration_utils.py:868] 2024-10-23 15:02:19,872 >> Configuration saved in ./output/checkpoint-1000/generation_config.json\n[INFO|modeling_utils.py:2836] 2024-10-23 15:02:20,875 >> Model weights saved in ./output/checkpoint-1000/model.safetensors\n[INFO|tokenization_utils_base.py:2649] 2024-10-23 15:02:20,877 >> tokenizer config file saved in ./output/checkpoint-1000/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2658] 2024-10-23 15:02:20,879 >> Special tokens file saved in ./output/checkpoint-1000/special_tokens_map.json\n[INFO|trainer.py:3797] 2024-10-23 15:02:22,269 >> Deleting older checkpoint [output/checkpoint-500] due to args.save_total_limit\n[INFO|trainer.py:3705] 2024-10-23 15:06:12,008 >> Saving model checkpoint to ./output/checkpoint-1374\n[INFO|configuration_utils.py:407] 2024-10-23 15:06:12,013 >> Configuration saved in ./output/checkpoint-1374/config.json\n[INFO|configuration_utils.py:868] 2024-10-23 15:06:12,015 >> Configuration saved in ./output/checkpoint-1374/generation_config.json\n[INFO|modeling_utils.py:2836] 2024-10-23 15:06:13,018 >> Model weights saved in ./output/checkpoint-1374/model.safetensors\n[INFO|tokenization_utils_base.py:2649] 2024-10-23 15:06:13,021 >> tokenizer config file saved in ./output/checkpoint-1374/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2658] 2024-10-23 15:06:13,022 >> Special tokens file saved in ./output/checkpoint-1374/special_tokens_map.json\n[INFO|trainer.py:3797] 2024-10-23 15:06:14,436 >> Deleting older checkpoint [output/checkpoint-1000] due to args.save_total_limit\n[INFO|trainer.py:4021] 2024-10-23 15:06:14,634 >> \n***** Running Evaluation *****\n[INFO|trainer.py:4023] 2024-10-23 15:06:14,636 >>   Num examples = 917\n[INFO|trainer.py:4026] 2024-10-23 15:06:14,637 >>   Batch size = 8\n[INFO|trainer.py:2505] 2024-10-23 15:06:38,973 >> \n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n[INFO|trainer.py:3705] 2024-10-23 15:06:38,980 >> Saving model checkpoint to ./output\n[INFO|configuration_utils.py:407] 2024-10-23 15:06:38,985 >> Configuration saved in ./output/config.json\n[INFO|configuration_utils.py:868] 2024-10-23 15:06:38,987 >> Configuration saved in ./output/generation_config.json\n[INFO|modeling_utils.py:2836] 2024-10-23 15:06:40,045 >> Model weights saved in ./output/model.safetensors\n[INFO|tokenization_utils_base.py:2649] 2024-10-23 15:06:40,048 >> tokenizer config file saved in ./output/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2658] 2024-10-23 15:06:40,049 >> Special tokens file saved in ./output/special_tokens_map.json\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "***** eval metrics *****\n  eval_loss                   =     4.3906\n  eval_model_preparation_time =     0.0038\n  eval_runtime                = 0:00:25.10\n  eval_samples_per_second     =     36.533\n  eval_steps_per_second       =      4.582\n***** train metrics *****\n  epoch                    =        3.0\n  total_flos               =  2674823GF\n  train_loss               =     3.6916\n  train_runtime            = 0:15:23.85\n  train_samples_per_second =     11.898\n  train_steps_per_second   =      1.487\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(Label(value='0.038 MB of 0.038 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbe37417294d420bbcbc9dd04fa0cc5a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▂▁▁</td></tr><tr><td>eval/model_preparation_time</td><td>▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>█▁▁▁</td></tr><tr><td>eval/samples_per_second</td><td>▁███</td></tr><tr><td>eval/steps_per_second</td><td>▁███</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▃▃▄▄▅▅▅▆▆▇███</td></tr><tr><td>train/global_step</td><td>▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇███</td></tr><tr><td>train/grad_norm</td><td>▅█▄▂▁▂▄▁▄▃▂▃▁</td></tr><tr><td>train/learning_rate</td><td>█▇▇▆▆▅▅▄▃▃▂▂▁</td></tr><tr><td>train/loss</td><td>█▆▆▅▄▃▃▃▃▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>3.61567</td></tr><tr><td>eval/model_preparation_time</td><td>0.0038</td></tr><tr><td>eval/runtime</td><td>24.3313</td></tr><tr><td>eval/samples_per_second</td><td>37.688</td></tr><tr><td>eval/steps_per_second</td><td>4.726</td></tr><tr><td>total_flos</td><td>2872070148980736.0</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>1374</td></tr><tr><td>train/grad_norm</td><td>1.80693</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>3.5091</td></tr><tr><td>train_loss</td><td>3.69157</td></tr><tr><td>train_runtime</td><td>923.8581</td></tr><tr><td>train_samples_per_second</td><td>11.898</td></tr><tr><td>train_steps_per_second</td><td>1.487</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">golden-thunder-4</strong> at: <a href='https://wandb.ai/csn2506-diem/Chapter4-1-basic/runs/7484mlih' target=\"_blank\">https://wandb.ai/csn2506-diem/Chapter4-1-basic/runs/7484mlih</a><br/> View project at: <a href='https://wandb.ai/csn2506-diem/Chapter4-1-basic' target=\"_blank\">https://wandb.ai/csn2506-diem/Chapter4-1-basic</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20241023_145026-7484mlih/logs</code>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WANDB\n",
        "## eval/loss\n",
        "https://wandb.ai/csn2506-diem/Chapter4-1-basic/reports/eval-loss-24-10-24-00-14-31---Vmlldzo5ODUwOTgz\n",
        "\n",
        "## train/loss\n",
        "https://wandb.ai/csn2506-diem/Chapter4-1-basic/reports/train-loss-24-10-24-00-15-20---Vmlldzo5ODUxMDAz\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hCRHJ_QP8Rxr"
      }
    }
  ]
}